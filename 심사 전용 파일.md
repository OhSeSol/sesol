
    필요한 모듈 호출


```python
import os
import pandas as pd
import numpy as np
```

    기본 디렉토리를 현재 폴더의 상위 폴더로 지정


```python
os.chdir(os.pardir)
```

    train data 지정


```python
#train
activity = pd.read_csv('./raw/train_activity.csv')
trade = pd.read_csv('./raw/train_trade.csv')
pledge = pd.read_csv('./raw/train_pledge.csv')
payment = pd.read_csv('./raw/train_payment.csv')
combat = pd.read_csv('./raw/train_combat.csv')
```

# train_first login day:

    유저의 최초 접속 일자를 나타내는 변수를 생성한다.
    train_activity를 단일 acc_id를 기준으로 정렬하여 day 변수의 최솟값을 리스트에 저장한 후 dataframe으로 변환하였다. 


```python
first_login_day=[]
for i in activity['acc_id'].unique():
    first_login_day.append(activity.loc[activity['acc_id']==i]['day'].min())
```


```python
first_login_day = pd.DataFrame({'acc_id':activity['acc_id'].unique(), 'first_login_day':first_login_day})
```

# train_having pledge cnt

    유저가 28일 동안 가입했던 혈맹 개수 변수를 생성한다.
    train_pledge를 단일 acc_id를 기준으로 정렬하여 pledge_id의 unique값을 리스트에 저장한 후 dataframe으로 변환하였다.


```python
having_pledge_cnt=[]
for i in pledge['acc_id'].unique():
    having_pledge_cnt.append(len(pledge.loc[pledge['acc_id']==i]['pledge_id'].unique()))
```


```python
having_pledge_cnt = pd.DataFrame({'acc_id':pledge['acc_id'].unique(), 'having_pledge_cnt':having_pledge_cnt})
```

# train_login day

    유저가 28일 중 접속한 일수 변수를 생성한다.
    train_activity를 단일 acc_id를 기준으로 정렬하여 day 변수의 unique값의 길이를 리스트로 저장한 후 dataframe으로 변환하였다.


```python
login_day=[]
for i in activity['acc_id'].unique():
    login_day.append(len(activity.loc[activity['acc_id']==i]['day'].unique()))
```


```python
login_day = pd.DataFrame({'acc_id':activity['acc_id'].unique(), 'login_day':login_day})
```

# train_char cnt

    유저가 가진 캐릭터의 개수 변수를 생성한다.
    train_activity를 단일 acc_id를 기준으로 정렬하여 char_id 변수의 unique값의 길이를 리스트로 저장한 후 dataframe으로 변환하였다.


```python
char_cnt=[]
for i in activity['acc_id'].unique():
    char_cnt.append(len(activity.loc[activity['acc_id']==i]['char_id'].unique()))
```


```python
char_cnt = pd.DataFrame({'acc_id':activity['acc_id'].unique(), 'char_cnt':char_cnt})
```

# train_num payment

    유저가 28일 간 과금한 횟수 변수를 생성한다.
    train_payment를 acc_id를 기준으로 정렬하여 day 변수의 unique값의 길이를 리스트로 저장한 후 dataframe으로 변환하였다. 


```python
num_payment=[]
for i in payment['acc_id'].unique():
    num_payment.append(len(payment.loc[payment['acc_id']==i]['day'].unique()))
```


```python
num_payment = pd.DataFrame({'acc_id':payment['acc_id'].unique(), 'num_payment':num_payment})
```

# train_amount spent sum

    유저가 28일 간 과금한 금액의 합 변수를 생성한다.
    train_payment의 amount_spent를 acc_id를 기준으로 합하였다.


```python
amount_spent_sum = payment.groupby('acc_id').sum()
del amount_spent_sum['day']
amount_spent_sum.rename({'amount_spent':'amount_spent_sum'}, axis=1, inplace=True)
amount_spent_sum.reset_index(inplace=True)
```

# train_level

    유저가 가진 캐릭터 별 최대 레벨의 합을 나타내는 변수를 생성한다.
    train_combat을 acc_id와 char_id를 기준으로 pivot table을 생성하여 다시 acc_id를 기준으로 level 변수를 합하였다.


```python
combat_pivot = combat.pivot_table(index=['acc_id','char_id'], aggfunc=max)
```


```python
level = pd.DataFrame(combat_pivot.groupby('acc_id').sum()['level']).reset_index()
```

# train_day01~28

    유저의 각 일자의 접속 시간 변수를 생성한다.
    train_activity를 acc_id 기준으로 day변수만 뽑아 정렬한 후 결측값을 0으로 대체하였다.


```python
day = activity.pivot_table(index='acc_id', columns='day', aggfunc=np.sum)['playtime'].fillna(0).reset_index()
```


```python
col = ["acc_id"]
for i in list(day.columns[1:]):
    if i <10:
        col.append("day0"+str(i))
    else :
        col.append("day"+str(i))
```


```python
day.columns = col
```

# train_target cnt/source cnt

    유저의 개인거래 판매/구매 횟수 변수를 생성한다.
    train_trade의 target_acc_id, source_acc_id 변수에 등장하는 값들을 각각 세어 dataframe으로 변환하였다. 


```python
source_cnt = pd.DataFrame(trade['source_acc_id'].value_counts()).reset_index()
target_cnt = pd.DataFrame(trade['target_acc_id'].value_counts()).reset_index()
```


```python
source_cnt.rename({'index':'acc_id', 'source_acc_id':'source_cnt'}, axis=1, inplace=True)
target_cnt.rename({'index':'acc_id', 'target_acc_id':'target_cnt'}, axis=1, inplace=True)
```

# train_combat sum

    train_combat에 존재하는 변수 중 day, char_id, server, class, level을 제외한 나머지 변수들을 acc_id를 기준으로 합하였다.


```python
combat.drop(['day', 'char_id', 'server', 'class', 'level'], axis=1, inplace=True)
```


```python
combat_sum = combat.pivot_table(index='acc_id', aggfunc=np.sum)
```


```python
combat_sum.reset_index(inplace=True)
```

# train_activity sum

    train_activity에 존재하는 변수 중 day, char_id, server, playtime, revive를 제외한 나머지 변수들을 acc_id를 기준으로 합하였다.
    단, game_money_change 변수는 단순히 합하게 되면 28일간의 아데나 손익을 나타내며 절댓값을 씌워 더하면 아데나의 총 변동량을 나타내어
    그 의미가 다르다고 판단해 각각 다른 변수로 생성하였다.


```python
activity.drop(['day', 'char_id', 'server', 'playtime', 'revive'], axis=1, inplace=True)
```


```python
activity['game_money_change_abs'] = np.abs(activity['game_money_change'])
```


```python
activity_sum = activity.groupby('acc_id').sum()
```


```python
activity_sum.rename({'private_shop':'private_shop_sum', 'fishing':'fishing_sum', 'solo_exp':'solo_exp_sum', 'party_exp':'party_exp_sum', 'quest_exp':'quest_exp_sum', 'npc_kill':'npc_kill_sum', 'rich_monster':'rich_monster_sum', 'death':'death_sum', 'exp_recovery':'exp_recovery_sum', 'game_money_change':'game_money_change_sum', 'game_money_change_abs':'game_money_change_abssum', 'enchant_count':'enchant_count_sum'}, axis=1, inplace=True)
```


```python
activity_sum.reset_index(inplace=True)
```

# train_pledge acted

    train_pledge를 단순히 acc_id 별로 가공 하기에는 다음과 같은 문제들이 존재한다.

    1. 여러 혈맹에 걸쳐 있었던 사람.
    2. 혈맹 id는 서버가 다르면 중복 될 수 있다. 
    3. 한 유저 아이디 안에 여러 캐릭터가 있으면 여러개의 혈맹이 있는데 어떻게 선택해야 하는가?
    4. activity를 확인한 결과 4만명의 모든 유저가 28일에는 접속
    
    해결책>
    1 > 여러 혈맹에 걸쳐있는 경우 어떤 기준으로 혈맹을 골라야할까? > 마지막 접속일의 혈맹 또는 가장 가까울때 혈맹
    2 > 서버마다 중복된다면 > 서버, 혈맹 아이디를 기준으로 데이터를 가공하면 됨
    3 > 한 유저가 여러 캐릭터로 여러 혈맹에 가입해 있다면 가장 활발한 혈맹을 기준으로
    4 > 28일에 혈맹이 있는 유저에 '혈맹의 활발한 정도'를 나타내는 변수를 부여하고 없는 경우 0으로 부여
    
    혈맹이 잔존 / 이탈 여부에 영향을 끼치는 정보를 단순히 예측기준일부터 가장 최근에 접속한 날짜에 "혈맹에 속해 있는지 아닌지"에 따라 1/0 이상의 정보를       주기 위해 다음과 같이 가공하였다.

     서버 > 혈맹 순으로 pivot table을 생성한 후 활동한 캐릭터 수로 나타낸 뒤 28일에 혈맹에 가입해 있던 유저만 추려낸다.
     그 후 유저가 가입한 기간 동안 접속한 유저의 수가 가장 많은 날을 뽑아 혈맹의 활발한 정도로 나타내었다.


```python
pledge_act=pledge.pivot_table(index= ["server","pledge_id"],aggfunc=len)
pledge_act=pledge_act.reset_index()
pledge_act=pledge_act.loc[:,["server","pledge_id","acc_id"]]
pledge_act.columns= ['server', 'pledge_id', 'pledge_acted']
```


```python
day_28_pledge=pledge.loc[pledge.day==28,:]
```


```python
day_28_pledge1=day_28_pledge.pivot_table(index=["acc_id","server","char_id","pledge_id"]) 
day_28_pledge1=day_28_pledge1.reset_index()
day_28_pledge1=day_28_pledge1.loc[:,["acc_id","server","char_id","pledge_id"]]
```


```python
act_day28_join=pd.merge(day_28_pledge1,pledge_act,how="left",on = ["server","pledge_id"])
act_day28_join1=act_day28_join.pivot_table(index= ["acc_id"],aggfunc=max)
act_day28_join1=act_day28_join1.reset_index()
pledge_acted=act_day28_join1.loc[:,["acc_id","pledge_acted"]]
```

# train_merge

    현재까지 만든 모든 변수를 merge함수를 이용하여 acc_id를 기준으로 병합한다.
    이 때, 생성한 변수마다 sample의 수가 모두 다르므로 온전하게 40000개의 sample이 존재하는 level변수에 기준을 맞춰 병합하였다.
    그 후, 결측값이 생기는 부분은 값이 0이라는 뜻이므로 결측값을 0으로 처리하였다.


```python
train = level.merge(combat_sum, on='acc_id')
train = train.merge(target_cnt, on='acc_id', how='left')
train = train.merge(source_cnt, on='acc_id', how='left')
train = train.merge(activity_sum, on='acc_id', how='left')
train = train.merge(login_day, on='acc_id', how='left')
train = train.merge(char_cnt, on='acc_id', how='left')
train = train.merge(num_payment, on='acc_id', how='left')
train = train.merge(pledge_acted, on='acc_id', how='left')
train = train.merge(having_pledge_cnt, on='acc_id', how='left')
train = train.merge(first_login_day, on='acc_id', how='left')
train = train.merge(day, on='acc_id', how='left')
train = train.merge(amount_spent_sum, on='acc_id', how='left')
train.fillna(0, inplace=True)
```


```python
train.to_csv('./preprocess/train_preprocess_1.csv', index=False)
```

    train data의 전처리 과정을 마친 후 같은 방법으로 test data 역시 전처리 과정을 진행하였다.


```python
#test
test1_activity = pd.read_csv('./raw/test1_activity.csv')
test1_trade = pd.read_csv('./raw/test1_trade.csv')
test1_pledge = pd.read_csv('./raw/test1_pledge.csv')
test1_payment = pd.read_csv('./raw/test1_payment.csv')
test1_combat = pd.read_csv('./raw/test1_combat.csv')

test2_activity = pd.read_csv('./raw/test2_activity.csv')
test2_trade = pd.read_csv('./raw/test2_trade.csv')
test2_pledge = pd.read_csv('./raw/test2_pledge.csv')
test2_payment = pd.read_csv('./raw/test2_payment.csv')
test2_combat = pd.read_csv('./raw/test2_combat.csv')
```

# test_first login day


```python
test1_first_login_day=[]
for i in test1_activity['acc_id'].unique():
    test1_first_login_day.append(test1_activity.loc[test1_activity['acc_id']==i]['day'].min())

test2_first_login_day=[]
for i in test2_activity['acc_id'].unique():
    test2_first_login_day.append(test2_activity.loc[test2_activity['acc_id']==i]['day'].min())
```


```python
test1_first_login_day = pd.DataFrame({'acc_id':test1_activity['acc_id'].unique(), 'first_login_day':test1_first_login_day})

test2_first_login_day = pd.DataFrame({'acc_id':test2_activity['acc_id'].unique(), 'first_login_day':test2_first_login_day})
```

# test_having pledge cnt


```python
test1_having_pledge_cnt=[]
for i in test1_pledge['acc_id'].unique():
    test1_having_pledge_cnt.append(len(test1_pledge.loc[test1_pledge['acc_id']==i]['pledge_id'].unique()))

test2_having_pledge_cnt=[]
for i in test2_pledge['acc_id'].unique():
    test2_having_pledge_cnt.append(len(test2_pledge.loc[test2_pledge['acc_id']==i]['pledge_id'].unique()))
```


```python
test1_having_pledge_cnt = pd.DataFrame({'acc_id':test1_pledge['acc_id'].unique(), 'having_pledge_cnt':test1_having_pledge_cnt})

test2_having_pledge_cnt = pd.DataFrame({'acc_id':test2_pledge['acc_id'].unique(), 'having_pledge_cnt':test2_having_pledge_cnt})
```

# test_login day


```python
test1_login_day=[]
for i in test1_activity['acc_id'].unique():
    test1_login_day.append(len(test1_activity.loc[test1_activity['acc_id']==i]['day'].unique()))
    
test2_login_day=[]
for i in test2_activity['acc_id'].unique():
    test2_login_day.append(len(test2_activity.loc[test2_activity['acc_id']==i]['day'].unique()))
```


```python
test1_login_day = pd.DataFrame({'acc_id':test1_activity['acc_id'].unique(), 'login_day':test1_login_day})

test2_login_day = pd.DataFrame({'acc_id':test2_activity['acc_id'].unique(), 'login_day':test2_login_day})
```

# test_char cnt


```python
test1_char_cnt=[]
for i in test1_activity['acc_id'].unique():
    test1_char_cnt.append(len(test1_activity.loc[test1_activity['acc_id']==i]['char_id'].unique()))
    
test2_char_cnt=[]
for i in test2_activity['acc_id'].unique():
    test2_char_cnt.append(len(test2_activity.loc[test2_activity['acc_id']==i]['char_id'].unique()))
```


```python
test1_char_cnt = pd.DataFrame({'acc_id':test1_activity['acc_id'].unique(), 'char_cnt':test1_char_cnt})

test2_char_cnt = pd.DataFrame({'acc_id':test2_activity['acc_id'].unique(), 'char_cnt':test2_char_cnt})
```

# test_num payment


```python
test1_num_payment=[]
for i in test1_payment['acc_id'].unique():
    test1_num_payment.append(len(test1_payment.loc[test1_payment['acc_id']==i]['day'].unique()))
    
test2_num_payment=[]
for i in test2_payment['acc_id'].unique():
    test2_num_payment.append(len(test2_payment.loc[test2_payment['acc_id']==i]['day'].unique()))
```


```python
test1_num_payment = pd.DataFrame({'acc_id':test1_payment['acc_id'].unique(), 'num_payment':test1_num_payment})

test2_num_payment = pd.DataFrame({'acc_id':test2_payment['acc_id'].unique(), 'num_payment':test2_num_payment})
```

# test_amount spent sum


```python
test1_amount_spent_sum = test1_payment.groupby('acc_id').sum()
del test1_amount_spent_sum['day']
test1_amount_spent_sum.rename({'amount_spent':'amount_spent_sum'}, axis=1, inplace=True)
test1_amount_spent_sum.reset_index(inplace=True)

test2_amount_spent_sum = test2_payment.groupby('acc_id').sum()
del test2_amount_spent_sum['day']
test2_amount_spent_sum.rename({'amount_spent':'amount_spent_sum'}, axis=1, inplace=True)
test2_amount_spent_sum.reset_index(inplace=True)
```

# test_level


```python
test1_combat_pivot = test1_combat.pivot_table(index=['acc_id','char_id'], aggfunc=max)

test2_combat_pivot = test2_combat.pivot_table(index=['acc_id','char_id'], aggfunc=max)
```


```python
test1_level = pd.DataFrame(test1_combat_pivot.groupby('acc_id').sum()['level']).reset_index()

test2_level = pd.DataFrame(test2_combat_pivot.groupby('acc_id').sum()['level']).reset_index()
```

# test_day01~28


```python
test1_day = test1_activity.pivot_table(index='acc_id', columns='day', aggfunc=np.sum)['playtime'].fillna(0).reset_index()

test2_day = test2_activity.pivot_table(index='acc_id', columns='day', aggfunc=np.sum)['playtime'].fillna(0).reset_index()
```


```python
test1_col = ["acc_id"]
for i in list(test1_day.columns[1:]):
    if i <10:
        test1_col.append("day0"+str(i))
    else :
        test1_col.append("day"+str(i))

test2_col = ["acc_id"]
for i in list(test2_day.columns[1:]):
    if i <10:
        test2_col.append("day0"+str(i))
    else :
        test2_col.append("day"+str(i))
```


```python
test1_day.columns = test1_col

test2_day.columns = test2_col
```

# test_target cnt/source cnt


```python
test1_source_cnt = pd.DataFrame(test1_trade['source_acc_id'].value_counts()).reset_index()
test1_target_cnt = pd.DataFrame(test1_trade['target_acc_id'].value_counts()).reset_index()

test2_source_cnt = pd.DataFrame(test2_trade['source_acc_id'].value_counts()).reset_index()
test2_target_cnt = pd.DataFrame(test2_trade['target_acc_id'].value_counts()).reset_index()
```


```python
test1_source_cnt.rename({'index':'acc_id', 'source_acc_id':'source_cnt'}, axis=1, inplace=True)
test1_target_cnt.rename({'index':'acc_id', 'target_acc_id':'target_cnt'}, axis=1, inplace=True)

test2_source_cnt.rename({'index':'acc_id', 'source_acc_id':'source_cnt'}, axis=1, inplace=True)
test2_target_cnt.rename({'index':'acc_id', 'target_acc_id':'target_cnt'}, axis=1, inplace=True)
```

# test_combat sum


```python
test1_combat.drop(['day', 'char_id', 'server', 'class', 'level'], axis=1, inplace=True)

test2_combat.drop(['day', 'char_id', 'server', 'class', 'level'], axis=1, inplace=True)
```


```python
test1_combat_sum = test1_combat.pivot_table(index='acc_id', aggfunc=np.sum)

test2_combat_sum = test2_combat.pivot_table(index='acc_id', aggfunc=np.sum)
```


```python
test1_combat_sum.reset_index(inplace=True)

test2_combat_sum.reset_index(inplace=True)
```

# test_activity sum


```python
test1_activity.drop(['day', 'char_id', 'server', 'playtime', 'revive'], axis=1, inplace=True)

test2_activity.drop(['day', 'char_id', 'server', 'playtime', 'revive'], axis=1, inplace=True)
```


```python
test1_activity['game_money_change_abs'] = np.abs(test1_activity['game_money_change'])

test2_activity['game_money_change_abs'] = np.abs(test2_activity['game_money_change'])
```


```python
test1_activity_sum = test1_activity.groupby('acc_id').sum()

test2_activity_sum = test2_activity.groupby('acc_id').sum()
```


```python
test1_activity_sum.rename({'private_shop':'private_shop_sum', 'fishing':'fishing_sum', 'solo_exp':'solo_exp_sum', 'party_exp':'party_exp_sum', 'quest_exp':'quest_exp_sum', 'npc_kill':'npc_kill_sum', 'rich_monster':'rich_monster_sum', 'death':'death_sum', 'exp_recovery':'exp_recovery_sum', 'game_money_change':'game_money_change_sum', 'game_money_change_abs':'game_money_change_abssum', 'enchant_count':'enchant_count_sum'}, axis=1, inplace=True)

test2_activity_sum.rename({'private_shop':'private_shop_sum', 'fishing':'fishing_sum', 'solo_exp':'solo_exp_sum', 'party_exp':'party_exp_sum', 'quest_exp':'quest_exp_sum', 'npc_kill':'npc_kill_sum', 'rich_monster':'rich_monster_sum', 'death':'death_sum', 'exp_recovery':'exp_recovery_sum', 'game_money_change':'game_money_change_sum', 'game_money_change_abs':'game_money_change_abssum', 'enchant_count':'enchant_count_sum'}, axis=1, inplace=True)
```


```python
test1_activity_sum.reset_index(inplace=True)

test2_activity_sum.reset_index(inplace=True)
```

# test_pledge acted


```python
test1_pledge_act=test1_pledge.pivot_table(index= ["server","pledge_id"],aggfunc=len)
test1_pledge_act=test1_pledge_act.reset_index()
test1_pledge_act=test1_pledge_act.loc[:,["server","pledge_id","acc_id"]]
test1_pledge_act.columns= ['server', 'pledge_id', 'pledge_acted']

test2_pledge_act=test2_pledge.pivot_table(index= ["server","pledge_id"],aggfunc=len)
test2_pledge_act=test2_pledge_act.reset_index()
test2_pledge_act=test2_pledge_act.loc[:,["server","pledge_id","acc_id"]]
test2_pledge_act.columns= ['server', 'pledge_id', 'pledge_acted']
```


```python
test1_pledge_act=test1_pledge.pivot_table(index= ["server","pledge_id"],aggfunc=len) #기간동안 각 서버의 혈맹별로 활동안 인원수만큼 활발한 정도로 파악하고 따짐
test1_pledge_act=test1_pledge_act.reset_index()
test1_pledge_act=test1_pledge_act.loc[:,["server","pledge_id","acc_id"]]
test1_pledge_act.columns= ['server', 'pledge_id', 'pledge_acted']
```


```python
test1_day_28_pledge=test1_pledge.loc[test1_pledge.day==28,:]

test2_day_28_pledge=test2_pledge.loc[test2_pledge.day==28,:]
```


```python
test1_day_28_pledge1=test1_day_28_pledge.pivot_table(index=["acc_id","server","char_id","pledge_id"]) 
test1_day_28_pledge1=test1_day_28_pledge1.reset_index()
test1_day_28_pledge1=test1_day_28_pledge1.loc[:,["acc_id","server","char_id","pledge_id"]]

test2_day_28_pledge1=test2_day_28_pledge.pivot_table(index=["acc_id","server","char_id","pledge_id"]) 
test2_day_28_pledge1=test2_day_28_pledge1.reset_index()
test2_day_28_pledge1=test2_day_28_pledge1.loc[:,["acc_id","server","char_id","pledge_id"]]
```


```python
test1_act_day28_join=pd.merge(test1_day_28_pledge1,test1_pledge_act,how="left",on = ["server","pledge_id"])
test1_act_day28_join1=test1_act_day28_join.pivot_table(index= ["acc_id"],aggfunc=max)
test1_act_day28_join1=test1_act_day28_join1.reset_index()
test1_pledge_acted=test1_act_day28_join1.loc[:,["acc_id","pledge_acted"]]

test2_act_day28_join=pd.merge(test2_day_28_pledge1,test2_pledge_act,how="left",on = ["server","pledge_id"])
test2_act_day28_join1=test2_act_day28_join.pivot_table(index= ["acc_id"],aggfunc=max)
test2_act_day28_join1=test2_act_day28_join1.reset_index()
test2_pledge_acted=test2_act_day28_join1.loc[:,["acc_id","pledge_acted"]]
```

    c:\users\tpthf\appdata\local\programs\python\python36\lib\site-packages\pandas\core\indexing.py:1494: FutureWarning: 
    Passing list-likes to .loc or [] with any missing label will raise
    KeyError in the future, you can use .reindex() as an alternative.
    
    See the documentation here:
    https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike
      return self._getitem_tuple(key)
    


```python
test1_day_28_pledge
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>day</th>
      <th>acc_id</th>
      <th>char_id</th>
      <th>server</th>
      <th>pledge_id</th>
      <th>play_char_cnt</th>
      <th>combat_char_cnt</th>
      <th>pledge_combat_cnt</th>
      <th>random_attacker_cnt</th>
      <th>random_defender_cnt</th>
      <th>same_pledge_cnt</th>
      <th>temp_cnt</th>
      <th>etc_cnt</th>
      <th>combat_play_time</th>
      <th>non_combat_play_time</th>
    </tr>
  </thead>
  <tbody>
  </tbody>
</table>
</div>



# test_merge


```python
test1 = test1_level.merge(test1_combat_sum, on='acc_id')
test1 = test1.merge(test1_target_cnt, on='acc_id', how='left')
test1 = test1.merge(test1_source_cnt, on='acc_id', how='left')
test1 = test1.merge(test1_activity_sum, on='acc_id', how='left')
test1 = test1.merge(test1_login_day, on='acc_id', how='left')
test1 = test1.merge(test1_char_cnt, on='acc_id', how='left')
test1 = test1.merge(test1_num_payment, on='acc_id', how='left')
test1 = test1.merge(test1_pledge_acted, on='acc_id', how='left')
test1 = test1.merge(test1_having_pledge_cnt, on='acc_id', how='left')
test1 = test1.merge(test1_first_login_day, on='acc_id', how='left')
test1 = test1.merge(test1_day, on='acc_id', how='left')
test1 = test1.merge(test1_amount_spent_sum, on='acc_id', how='left')
test1.fillna(0, inplace=True)

test2 = test2_level.merge(test2_combat_sum, on='acc_id')
test2 = test2.merge(test2_target_cnt, on='acc_id', how='left')
test2 = test2.merge(test2_source_cnt, on='acc_id', how='left')
test2 = test2.merge(test2_activity_sum, on='acc_id', how='left')
test2 = test2.merge(test2_login_day, on='acc_id', how='left')
test2 = test2.merge(test2_char_cnt, on='acc_id', how='left')
test2 = test2.merge(test2_num_payment, on='acc_id', how='left')
test2 = test2.merge(test2_pledge_acted, on='acc_id', how='left')
test2 = test2.merge(test2_having_pledge_cnt, on='acc_id', how='left')
test2 = test2.merge(test2_first_login_day, on='acc_id', how='left')
test2 = test2.merge(test2_day, on='acc_id', how='left')
test2 = test2.merge(test2_amount_spent_sum, on='acc_id', how='left')
test2.fillna(0, inplace=True)
```


```python
test1.to_csv('./preprocess/test1_preprocess_1.csv', index=False)

test2.to_csv('./preprocess/test2_preprocess_1.csv', index=False)
```


```python

```
![1](https://user-images.githubusercontent.com/49121293/64578177-985aaa80-d3b9-11e9-8eb7-abd80dc075dc.jpg)

